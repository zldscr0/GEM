{'data_root': '/data/bzx_yjy/cifar100', 'image_size': 32, 'pin_memory': False, 'augment': True, 'workers': 8, 'device_ids': 0, 'n_gpu': 1, 'seed': 1993, 'deterministic': True, 'epoch': 170, 'batch_size': 128, 'val_per_epoch': 10, 'optimzer': {'name': 'SGD', 'kwargs': {'lr': 0.1}}, 'lr_scheduler': {'name': 'StepLR', 'kwargs': {'gamma': 0.1, 'step_size': 80}}, 'warmup': 3, 'includes': ['headers/data.yaml', 'headers/device.yaml', 'headers/model.yaml', 'headers/optimizer.yaml', 'backbones/resnet12.yaml'], 'save_path': './', 'init_cls_num': 20, 'inc_cls_num': 20, 'task_num': 5, 'optimizer': {'name': 'SGD', 'kwargs': {'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0002}}, 'backbone': {'name': 'resnet34', 'kwargs': {'num_classes': 100, 'args': {'dataset': 'cifar100'}}}, 'buffer': {'name': 'LinearBuffer', 'kwargs': {'buffer_size': 0, 'batch_size': 32, 'strategy': 'random'}}, 'classifier': {'name': 'GEM', 'kwargs': {'num_class': 100, 'feat_dim': 512, 'n_memories': 5120, 'n_task': 5, 'memory_strength': 0}}, 'rank': 0}
GEM(
  (net): ResNet(
    (conv1): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (classifier): Linear(in_features=512, out_features=100, bias=True)
  (ce): CrossEntropyLoss()
)
Trainable params in the model: 21328292
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.03333333333333333
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0002
)
================Task 0 Start!================
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.03333333333333333
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0002
)
================Task 0 Training!================
The training samples number: 10000
learning rate: [0.03333333333333333]
================ Train on the train set ================
Epoch [0/170] |	Loss: 2.823 	Average Acc: 0.162 
learning rate: [0.06666666666666667]
================ Train on the train set ================
Epoch [1/170] |	Loss: 2.426 	Average Acc: 0.262 
learning rate: [0.1]
================ Train on the train set ================
Epoch [2/170] |	Loss: 2.222 	Average Acc: 0.321 
learning rate: [0.1]
================ Train on the train set ================
Epoch [3/170] |	Loss: 1.963 	Average Acc: 0.398 
learning rate: [0.1]
================ Train on the train set ================
Epoch [4/170] |	Loss: 1.767 	Average Acc: 0.453 
learning rate: [0.1]
================ Train on the train set ================
Epoch [5/170] |	Loss: 1.577 	Average Acc: 0.514 
learning rate: [0.1]
================ Train on the train set ================
Epoch [6/170] |	Loss: 1.378 	Average Acc: 0.569 
learning rate: [0.1]
================ Train on the train set ================
Epoch [7/170] |	Loss: 1.180 	Average Acc: 0.627 
learning rate: [0.1]
================ Train on the train set ================
Epoch [8/170] |	Loss: 0.997 	Average Acc: 0.681 
learning rate: [0.1]
================ Train on the train set ================
Epoch [9/170] |	Loss: 0.816 	Average Acc: 0.740 
================ Test on the test set ================
 * Average Acc: 0.550 Best acc 0.550
 Per-Task Acc:[0.55]
learning rate: [0.1]
================ Train on the train set ================
Epoch [10/170] |	Loss: 0.666 	Average Acc: 0.786 
learning rate: [0.1]
================ Train on the train set ================
Epoch [11/170] |	Loss: 0.508 	Average Acc: 0.836 
learning rate: [0.1]
================ Train on the train set ================
Epoch [12/170] |	Loss: 0.419 	Average Acc: 0.862 
learning rate: [0.1]
================ Train on the train set ================
Epoch [13/170] |	Loss: 0.305 	Average Acc: 0.902 
learning rate: [0.1]
================ Train on the train set ================
Epoch [14/170] |	Loss: 0.256 	Average Acc: 0.917 
learning rate: [0.1]
================ Train on the train set ================
Epoch [15/170] |	Loss: 0.220 	Average Acc: 0.927 
learning rate: [0.1]
================ Train on the train set ================
Epoch [16/170] |	Loss: 0.221 	Average Acc: 0.926 
learning rate: [0.1]
================ Train on the train set ================
Epoch [17/170] |	Loss: 0.194 	Average Acc: 0.938 
learning rate: [0.1]
================ Train on the train set ================
Epoch [18/170] |	Loss: 0.168 	Average Acc: 0.947 
learning rate: [0.1]
================ Train on the train set ================
Epoch [19/170] |	Loss: 0.168 	Average Acc: 0.945 
================ Test on the test set ================
 * Average Acc: 0.560 Best acc 0.560
 Per-Task Acc:[0.56]
learning rate: [0.1]
================ Train on the train set ================
Epoch [20/170] |	Loss: 0.190 	Average Acc: 0.938 
learning rate: [0.1]
================ Train on the train set ================
Epoch [21/170] |	Loss: 0.178 	Average Acc: 0.944 
learning rate: [0.1]
================ Train on the train set ================
Epoch [22/170] |	Loss: 0.150 	Average Acc: 0.951 
learning rate: [0.1]
================ Train on the train set ================
Epoch [23/170] |	Loss: 0.160 	Average Acc: 0.948 
learning rate: [0.1]
================ Train on the train set ================
Epoch [24/170] |	Loss: 0.135 	Average Acc: 0.957 
learning rate: [0.1]
================ Train on the train set ================
Epoch [25/170] |	Loss: 0.150 	Average Acc: 0.952 
learning rate: [0.1]
================ Train on the train set ================
Epoch [26/170] |	Loss: 0.157 	Average Acc: 0.949 
learning rate: [0.1]
================ Train on the train set ================
Epoch [27/170] |	Loss: 0.156 	Average Acc: 0.949 
learning rate: [0.1]
================ Train on the train set ================
Epoch [28/170] |	Loss: 0.148 	Average Acc: 0.952 
learning rate: [0.1]
================ Train on the train set ================
Epoch [29/170] |	Loss: 0.155 	Average Acc: 0.949 
================ Test on the test set ================
 * Average Acc: 0.590 Best acc 0.590
 Per-Task Acc:[0.59]
learning rate: [0.1]
================ Train on the train set ================
Epoch [30/170] |	Loss: 0.150 	Average Acc: 0.952 
learning rate: [0.1]
================ Train on the train set ================
Epoch [31/170] |	Loss: 0.153 	Average Acc: 0.951 
learning rate: [0.1]
================ Train on the train set ================
Epoch [32/170] |	Loss: 0.124 	Average Acc: 0.961 
learning rate: [0.1]
================ Train on the train set ================
Epoch [33/170] |	Loss: 0.142 	Average Acc: 0.954 
learning rate: [0.1]
================ Train on the train set ================
Epoch [34/170] |	Loss: 0.149 	Average Acc: 0.952 
learning rate: [0.1]
================ Train on the train set ================
Epoch [35/170] |	Loss: 0.134 	Average Acc: 0.958 
learning rate: [0.1]
================ Train on the train set ================
Epoch [36/170] |	Loss: 0.159 	Average Acc: 0.948 
learning rate: [0.1]
================ Train on the train set ================
Epoch [37/170] |	Loss: 0.125 	Average Acc: 0.960 
learning rate: [0.1]
================ Train on the train set ================
Epoch [38/170] |	Loss: 0.154 	Average Acc: 0.951 
learning rate: [0.1]
================ Train on the train set ================
Epoch [39/170] |	Loss: 0.161 	Average Acc: 0.948 
================ Test on the test set ================
 * Average Acc: 0.560 Best acc 0.590
 Per-Task Acc:[0.56]
learning rate: [0.1]
================ Train on the train set ================
Epoch [40/170] |	Loss: 0.134 	Average Acc: 0.957 
learning rate: [0.1]
================ Train on the train set ================
Epoch [41/170] |	Loss: 0.123 	Average Acc: 0.962 
learning rate: [0.1]
================ Train on the train set ================
Epoch [42/170] |	Loss: 0.137 	Average Acc: 0.956 
learning rate: [0.1]
================ Train on the train set ================
Epoch [43/170] |	Loss: 0.136 	Average Acc: 0.957 
learning rate: [0.1]
================ Train on the train set ================
Epoch [44/170] |	Loss: 0.154 	Average Acc: 0.953 
learning rate: [0.1]
================ Train on the train set ================
Epoch [45/170] |	Loss: 0.159 	Average Acc: 0.949 
learning rate: [0.1]
================ Train on the train set ================
Epoch [46/170] |	Loss: 0.175 	Average Acc: 0.945 
learning rate: [0.1]
================ Train on the train set ================
Epoch [47/170] |	Loss: 0.112 	Average Acc: 0.964 
learning rate: [0.1]
================ Train on the train set ================
Epoch [48/170] |	Loss: 0.140 	Average Acc: 0.956 
learning rate: [0.1]
================ Train on the train set ================
Epoch [49/170] |	Loss: 0.134 	Average Acc: 0.958 
================ Test on the test set ================
 * Average Acc: 0.570 Best acc 0.590
 Per-Task Acc:[0.57]
learning rate: [0.1]
================ Train on the train set ================
Epoch [50/170] |	Loss: 0.104 	Average Acc: 0.967 
learning rate: [0.1]
================ Train on the train set ================
Epoch [51/170] |	Loss: 0.142 	Average Acc: 0.954 
learning rate: [0.1]
================ Train on the train set ================
Epoch [52/170] |	Loss: 0.163 	Average Acc: 0.951 
learning rate: [0.1]
================ Train on the train set ================
Epoch [53/170] |	Loss: 0.157 	Average Acc: 0.950 
learning rate: [0.1]
================ Train on the train set ================
Epoch [54/170] |	Loss: 0.140 	Average Acc: 0.956 
learning rate: [0.1]
================ Train on the train set ================
Epoch [55/170] |	Loss: 0.121 	Average Acc: 0.962 
learning rate: [0.1]
================ Train on the train set ================
Epoch [56/170] |	Loss: 0.112 	Average Acc: 0.966 
learning rate: [0.1]
================ Train on the train set ================
Epoch [57/170] |	Loss: 0.163 	Average Acc: 0.947 
learning rate: [0.1]
================ Train on the train set ================
Epoch [58/170] |	Loss: 0.149 	Average Acc: 0.954 
learning rate: [0.1]
================ Train on the train set ================
Epoch [59/170] |	Loss: 0.118 	Average Acc: 0.961 
================ Test on the test set ================
 * Average Acc: 0.550 Best acc 0.590
 Per-Task Acc:[0.55]
learning rate: [0.1]
================ Train on the train set ================
Epoch [60/170] |	Loss: 0.164 	Average Acc: 0.950 
learning rate: [0.1]
================ Train on the train set ================
Epoch [61/170] |	Loss: 0.097 	Average Acc: 0.969 
learning rate: [0.1]
================ Train on the train set ================
Epoch [62/170] |	Loss: 0.148 	Average Acc: 0.954 
learning rate: [0.1]
================ Train on the train set ================
Epoch [63/170] |	Loss: 0.165 	Average Acc: 0.948 
learning rate: [0.1]
================ Train on the train set ================
Epoch [64/170] |	Loss: 0.124 	Average Acc: 0.958 
learning rate: [0.1]
================ Train on the train set ================
Epoch [65/170] |	Loss: 0.121 	Average Acc: 0.963 
learning rate: [0.1]
================ Train on the train set ================
Epoch [66/170] |	Loss: 0.131 	Average Acc: 0.959 
learning rate: [0.1]
================ Train on the train set ================
Epoch [67/170] |	Loss: 0.135 	Average Acc: 0.956 
learning rate: [0.1]
================ Train on the train set ================
Epoch [68/170] |	Loss: 0.140 	Average Acc: 0.957 
learning rate: [0.1]
================ Train on the train set ================
Epoch [69/170] |	Loss: 0.094 	Average Acc: 0.969 
================ Test on the test set ================
 * Average Acc: 0.580 Best acc 0.590
 Per-Task Acc:[0.58]
learning rate: [0.1]
================ Train on the train set ================
Epoch [70/170] |	Loss: 0.133 	Average Acc: 0.956 
learning rate: [0.1]
================ Train on the train set ================
Epoch [71/170] |	Loss: 0.137 	Average Acc: 0.956 
learning rate: [0.1]
================ Train on the train set ================
Epoch [72/170] |	Loss: 0.135 	Average Acc: 0.957 
learning rate: [0.1]
================ Train on the train set ================
Epoch [73/170] |	Loss: 0.156 	Average Acc: 0.951 
learning rate: [0.1]
================ Train on the train set ================
Epoch [74/170] |	Loss: 0.112 	Average Acc: 0.963 
learning rate: [0.1]
================ Train on the train set ================
Epoch [75/170] |	Loss: 0.168 	Average Acc: 0.945 
learning rate: [0.1]
================ Train on the train set ================
Epoch [76/170] |	Loss: 0.088 	Average Acc: 0.974 
learning rate: [0.1]
================ Train on the train set ================
Epoch [77/170] |	Loss: 0.105 	Average Acc: 0.968 
learning rate: [0.1]
================ Train on the train set ================
Epoch [78/170] |	Loss: 0.151 	Average Acc: 0.952 
learning rate: [0.1]
================ Train on the train set ================
Epoch [79/170] |	Loss: 0.150 	Average Acc: 0.953 
================ Test on the test set ================
 * Average Acc: 0.590 Best acc 0.590
 Per-Task Acc:[0.59]
learning rate: [0.1]
================ Train on the train set ================
Epoch [80/170] |	Loss: 0.114 	Average Acc: 0.965 
learning rate: [0.1]
================ Train on the train set ================
Epoch [81/170] |	Loss: 0.136 	Average Acc: 0.958 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [82/170] |	Loss: 0.054 	Average Acc: 0.984 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [83/170] |	Loss: 0.010 	Average Acc: 0.999 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [84/170] |	Loss: 0.006 	Average Acc: 0.999 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [85/170] |	Loss: 0.004 	Average Acc: 1.000 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [86/170] |	Loss: 0.004 	Average Acc: 1.000 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [87/170] |	Loss: 0.003 	Average Acc: 1.000 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [88/170] |	Loss: 0.003 	Average Acc: 1.000 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [89/170] |	Loss: 0.002 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.660 Best acc 0.660
 Per-Task Acc:[0.66]
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [90/170] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.010000000000000002]
================ Train on the train set ================
