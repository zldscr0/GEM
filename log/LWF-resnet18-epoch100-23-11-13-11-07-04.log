{'data_root': '/data/bzx_yjy/cifar100', 'image_size': 32, 'pin_memory': False, 'augment': True, 'workers': 8, 'device_ids': 0, 'n_gpu': 1, 'seed': 1993, 'deterministic': True, 'epoch': 100, 'batch_size': 128, 'val_per_epoch': 10, 'optimzer': {'name': 'SGD', 'kwargs': {'lr': 0.1}}, 'lr_scheduler': {'name': 'StepLR', 'kwargs': {'gamma': 0.5, 'step_size': 30}}, 'warmup': 3, 'includes': ['headers/data.yaml', 'headers/device.yaml', 'headers/model.yaml', 'headers/optimizer.yaml', 'backbones/resnet12.yaml'], 'save_path': './', 'init_cls_num': 20, 'inc_cls_num': 20, 'task_num': 5, 'optimizer': {'name': 'SGD', 'kwargs': {'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0002}}, 'backbone': {'name': 'resnet18', 'kwargs': {'num_classes': 100, 'args': {'dataset': 'cifar100'}}}, 'buffer': {'name': 'LinearBuffer', 'kwargs': {'buffer_size': 0, 'batch_size': 32, 'strategy': 'random'}}, 'classifier': {'name': 'LWF', 'kwargs': {'num_class': 100, 'feat_dim': 512, 'init_cls_num': 20, 'inc_cls_num': 20, 'dist': 0.5, 'lamda': 10, 'K': 2, 'lw_mr': 1}}, 'rank': 0}
LWF(
  (backbone): ResNet(
    (conv1): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (classifier): None
  (loss_fn): CrossEntropyLoss()
)
Trainable params in the model: 11168832
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.03333333333333333
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0002
)
================Task 0 Start!================
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.03333333333333333
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0002
)
================Task 0 Training!================
The training samples number: 10000
learning rate: [0.03333333333333333]
================ Train on the train set ================
Epoch [0/100] |	Loss: 2.671 	Average Acc: 0.206 
learning rate: [0.06666666666666667]
================ Train on the train set ================
Epoch [1/100] |	Loss: 2.275 	Average Acc: 0.305 
learning rate: [0.1]
================ Train on the train set ================
Epoch [2/100] |	Loss: 2.041 	Average Acc: 0.371 
learning rate: [0.1]
================ Train on the train set ================
Epoch [3/100] |	Loss: 1.770 	Average Acc: 0.449 
learning rate: [0.1]
================ Train on the train set ================
Epoch [4/100] |	Loss: 1.517 	Average Acc: 0.528 
learning rate: [0.1]
================ Train on the train set ================
Epoch [5/100] |	Loss: 1.287 	Average Acc: 0.594 
learning rate: [0.1]
================ Train on the train set ================
Epoch [6/100] |	Loss: 1.087 	Average Acc: 0.656 
learning rate: [0.1]
================ Train on the train set ================
Epoch [7/100] |	Loss: 0.874 	Average Acc: 0.726 
learning rate: [0.1]
================ Train on the train set ================
Epoch [8/100] |	Loss: 0.719 	Average Acc: 0.767 
learning rate: [0.1]
================ Train on the train set ================
Epoch [9/100] |	Loss: 0.520 	Average Acc: 0.833 
================ Test on the test set ================
 * Average Acc: 0.600 Best acc 0.600
 Per-Task Acc:[0.6]
learning rate: [0.1]
================ Train on the train set ================
Epoch [10/100] |	Loss: 0.405 	Average Acc: 0.870 
learning rate: [0.1]
================ Train on the train set ================
Epoch [11/100] |	Loss: 0.301 	Average Acc: 0.900 
learning rate: [0.1]
================ Train on the train set ================
Epoch [12/100] |	Loss: 0.292 	Average Acc: 0.903 
learning rate: [0.1]
================ Train on the train set ================
Epoch [13/100] |	Loss: 0.239 	Average Acc: 0.924 
learning rate: [0.1]
================ Train on the train set ================
Epoch [14/100] |	Loss: 0.242 	Average Acc: 0.919 
learning rate: [0.1]
================ Train on the train set ================
Epoch [15/100] |	Loss: 0.211 	Average Acc: 0.929 
learning rate: [0.1]
================ Train on the train set ================
Epoch [16/100] |	Loss: 0.193 	Average Acc: 0.938 
learning rate: [0.1]
================ Train on the train set ================
Epoch [17/100] |	Loss: 0.161 	Average Acc: 0.951 
learning rate: [0.1]
================ Train on the train set ================
Epoch [18/100] |	Loss: 0.167 	Average Acc: 0.947 
learning rate: [0.1]
================ Train on the train set ================
Epoch [19/100] |	Loss: 0.184 	Average Acc: 0.940 
================ Test on the test set ================
 * Average Acc: 0.590 Best acc 0.600
 Per-Task Acc:[0.59]
learning rate: [0.1]
================ Train on the train set ================
Epoch [20/100] |	Loss: 0.159 	Average Acc: 0.951 
learning rate: [0.1]
================ Train on the train set ================
Epoch [21/100] |	Loss: 0.151 	Average Acc: 0.949 
learning rate: [0.1]
================ Train on the train set ================
Epoch [22/100] |	Loss: 0.191 	Average Acc: 0.938 
learning rate: [0.1]
================ Train on the train set ================
Epoch [23/100] |	Loss: 0.126 	Average Acc: 0.962 
learning rate: [0.1]
================ Train on the train set ================
Epoch [24/100] |	Loss: 0.138 	Average Acc: 0.957 
learning rate: [0.1]
================ Train on the train set ================
Epoch [25/100] |	Loss: 0.202 	Average Acc: 0.935 
learning rate: [0.1]
================ Train on the train set ================
Epoch [26/100] |	Loss: 0.171 	Average Acc: 0.941 
learning rate: [0.1]
================ Train on the train set ================
Epoch [27/100] |	Loss: 0.112 	Average Acc: 0.965 
learning rate: [0.1]
================ Train on the train set ================
Epoch [28/100] |	Loss: 0.156 	Average Acc: 0.951 
learning rate: [0.1]
================ Train on the train set ================
Epoch [29/100] |	Loss: 0.144 	Average Acc: 0.952 
================ Test on the test set ================
 * Average Acc: 0.590 Best acc 0.600
 Per-Task Acc:[0.59]
learning rate: [0.1]
================ Train on the train set ================
Epoch [30/100] |	Loss: 0.167 	Average Acc: 0.946 
learning rate: [0.1]
================ Train on the train set ================
Epoch [31/100] |	Loss: 0.130 	Average Acc: 0.961 
learning rate: [0.05]
================ Train on the train set ================
Epoch [32/100] |	Loss: 0.036 	Average Acc: 0.991 
learning rate: [0.05]
================ Train on the train set ================
Epoch [33/100] |	Loss: 0.005 	Average Acc: 0.999 
learning rate: [0.05]
================ Train on the train set ================
Epoch [34/100] |	Loss: 0.003 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [35/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [36/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [37/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [38/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [39/100] |	Loss: 0.002 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.670 Best acc 0.670
 Per-Task Acc:[0.67]
learning rate: [0.05]
================ Train on the train set ================
Epoch [40/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [41/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [42/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [43/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [44/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [45/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [46/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [47/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [48/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [49/100] |	Loss: 0.002 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.680 Best acc 0.680
 Per-Task Acc:[0.68]
learning rate: [0.05]
================ Train on the train set ================
Epoch [50/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [51/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [52/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [53/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [54/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [55/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [56/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [57/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [58/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [59/100] |	Loss: 0.002 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.680 Best acc 0.680
 Per-Task Acc:[0.68]
learning rate: [0.05]
================ Train on the train set ================
Epoch [60/100] |	Loss: 0.002 	Average Acc: 1.000 
learning rate: [0.05]
================ Train on the train set ================
Epoch [61/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [62/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [63/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [64/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [65/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [66/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [67/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [68/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [69/100] |	Loss: 0.001 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.690 Best acc 0.690
 Per-Task Acc:[0.69]
learning rate: [0.025]
================ Train on the train set ================
Epoch [70/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [71/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [72/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [73/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [74/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [75/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [76/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [77/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [78/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [79/100] |	Loss: 0.001 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.680 Best acc 0.690
 Per-Task Acc:[0.68]
learning rate: [0.025]
================ Train on the train set ================
Epoch [80/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [81/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [82/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
Epoch [83/100] |	Loss: 0.001 	Average Acc: 1.000 
learning rate: [0.025]
================ Train on the train set ================
