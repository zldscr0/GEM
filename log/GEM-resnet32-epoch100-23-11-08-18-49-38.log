{'data_root': '/data/bzx_yjy/cifar100', 'image_size': 32, 'pin_memory': False, 'augment': True, 'workers': 8, 'device_ids': 0, 'n_gpu': 1, 'seed': 1993, 'deterministic': True, 'epoch': 100, 'batch_size': 128, 'val_per_epoch': 5, 'optimzer': {'name': 'SGD', 'kwargs': {'lr': 0.1}}, 'lr_scheduler': {'name': 'StepLR', 'kwargs': {'gamma': 0.1, 'step_size': 80}}, 'warmup': 3, 'includes': ['headers/data.yaml', 'headers/device.yaml', 'headers/model.yaml', 'headers/optimizer.yaml', 'backbones/resnet12.yaml'], 'save_path': './', 'init_cls_num': 20, 'inc_cls_num': 20, 'task_num': 5, 'optimizer': {'name': 'SGD', 'kwargs': {'lr': 0.1, 'momentum': 0.95, 'weight_decay': 0.0002}}, 'backbone': {'name': 'resnet32', 'kwargs': None}, 'buffer': {'name': 'LinearBuffer', 'kwargs': {'buffer_size': 0, 'batch_size': 32, 'strategy': 'random'}}, 'classifier': {'name': 'GEM', 'kwargs': {'num_class': 100, 'feat_dim': 64, 'n_memories': 5120, 'n_task': 5, 'memory_strength': 0}}, 'rank': 0}
GEM(
  (net): CifarResNet(
    (conv_1_3x3): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (stage_1): Sequential(
      (0): ResNetBasicblock(
        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ResNetBasicblock(
        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): ResNetBasicblock(
        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): ResNetBasicblock(
        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): ResNetBasicblock(
        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (stage_2): Sequential(
      (0): ResNetBasicblock(
        (conv_a): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): DownsampleA(
          (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
        )
      )
      (1): ResNetBasicblock(
        (conv_a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): ResNetBasicblock(
        (conv_a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): ResNetBasicblock(
        (conv_a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): ResNetBasicblock(
        (conv_a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (stage_3): Sequential(
      (0): ResNetBasicblock(
        (conv_a): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): DownsampleA(
          (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
        )
      )
      (1): ResNetBasicblock(
        (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): ResNetBasicblock(
        (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): ResNetBasicblock(
        (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): ResNetBasicblock(
        (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
    (fc): Linear(in_features=64, out_features=10, bias=True)
  )
  (classifier): Linear(in_features=64, out_features=100, bias=True)
  (ce): CrossEntropyLoss()
)
Trainable params in the model: 470654
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.03333333333333333
    maximize: False
    momentum: 0.95
    nesterov: False
    weight_decay: 0.0002
)
================Task 0 Start!================
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.03333333333333333
    maximize: False
    momentum: 0.95
    nesterov: False
    weight_decay: 0.0002
)
================Task 0 Training!================
The training samples number: 10000
learning rate: [0.03333333333333333]
================ Train on the train set ================
Epoch [0/100] |	Loss: 2.838 	Average Acc: 0.138 
learning rate: [0.06666666666666667]
================ Train on the train set ================
Epoch [1/100] |	Loss: 2.486 	Average Acc: 0.237 
learning rate: [0.1]
================ Train on the train set ================
Epoch [2/100] |	Loss: 2.274 	Average Acc: 0.301 
learning rate: [0.1]
================ Train on the train set ================
Epoch [3/100] |	Loss: 2.049 	Average Acc: 0.365 
learning rate: [0.1]
================ Train on the train set ================
Epoch [4/100] |	Loss: 1.883 	Average Acc: 0.415 
================ Test on the test set ================
 * Average Acc: 0.400 Best acc 0.400
 Per-Task Acc:[0.4]
learning rate: [0.1]
================ Train on the train set ================
Epoch [5/100] |	Loss: 1.778 	Average Acc: 0.442 
learning rate: [0.1]
================ Train on the train set ================
Epoch [6/100] |	Loss: 1.651 	Average Acc: 0.486 
learning rate: [0.1]
================ Train on the train set ================
Epoch [7/100] |	Loss: 1.528 	Average Acc: 0.520 
learning rate: [0.1]
================ Train on the train set ================
Epoch [8/100] |	Loss: 1.460 	Average Acc: 0.544 
learning rate: [0.1]
================ Train on the train set ================
Epoch [9/100] |	Loss: 1.365 	Average Acc: 0.572 
================ Test on the test set ================
 * Average Acc: 0.530 Best acc 0.530
 Per-Task Acc:[0.53]
learning rate: [0.1]
================ Train on the train set ================
Epoch [10/100] |	Loss: 1.288 	Average Acc: 0.591 
learning rate: [0.1]
================ Train on the train set ================
Epoch [11/100] |	Loss: 1.214 	Average Acc: 0.616 
learning rate: [0.1]
================ Train on the train set ================
Epoch [12/100] |	Loss: 1.150 	Average Acc: 0.634 
learning rate: [0.1]
================ Train on the train set ================
Epoch [13/100] |	Loss: 1.101 	Average Acc: 0.649 
learning rate: [0.1]
================ Train on the train set ================
Epoch [14/100] |	Loss: 1.075 	Average Acc: 0.655 
================ Test on the test set ================
 * Average Acc: 0.580 Best acc 0.580
 Per-Task Acc:[0.58]
learning rate: [0.1]
================ Train on the train set ================
Epoch [15/100] |	Loss: 0.960 	Average Acc: 0.691 
learning rate: [0.1]
================ Train on the train set ================
Epoch [16/100] |	Loss: 0.965 	Average Acc: 0.690 
learning rate: [0.1]
================ Train on the train set ================
Epoch [17/100] |	Loss: 0.912 	Average Acc: 0.711 
learning rate: [0.1]
================ Train on the train set ================
Epoch [18/100] |	Loss: 0.851 	Average Acc: 0.731 
learning rate: [0.1]
================ Train on the train set ================
Epoch [19/100] |	Loss: 0.816 	Average Acc: 0.732 
================ Test on the test set ================
 * Average Acc: 0.560 Best acc 0.580
 Per-Task Acc:[0.56]
learning rate: [0.1]
================ Train on the train set ================
Epoch [20/100] |	Loss: 0.833 	Average Acc: 0.731 
learning rate: [0.1]
================ Train on the train set ================
Epoch [21/100] |	Loss: 0.764 	Average Acc: 0.749 
learning rate: [0.1]
================ Train on the train set ================
Epoch [22/100] |	Loss: 0.747 	Average Acc: 0.758 
learning rate: [0.1]
================ Train on the train set ================
Epoch [23/100] |	Loss: 0.727 	Average Acc: 0.764 
learning rate: [0.1]
================ Train on the train set ================
Epoch [24/100] |	Loss: 0.723 	Average Acc: 0.766 
================ Test on the test set ================
 * Average Acc: 0.590 Best acc 0.590
 Per-Task Acc:[0.59]
learning rate: [0.1]
================ Train on the train set ================
Epoch [25/100] |	Loss: 0.707 	Average Acc: 0.770 
learning rate: [0.1]
================ Train on the train set ================
Epoch [26/100] |	Loss: 0.648 	Average Acc: 0.790 
learning rate: [0.1]
================ Train on the train set ================
Epoch [27/100] |	Loss: 0.643 	Average Acc: 0.789 
learning rate: [0.1]
================ Train on the train set ================
Epoch [28/100] |	Loss: 0.672 	Average Acc: 0.780 
learning rate: [0.1]
================ Train on the train set ================
Epoch [29/100] |	Loss: 0.654 	Average Acc: 0.790 
================ Test on the test set ================
 * Average Acc: 0.540 Best acc 0.590
 Per-Task Acc:[0.54]
learning rate: [0.1]
================ Train on the train set ================
Epoch [30/100] |	Loss: 0.653 	Average Acc: 0.788 
learning rate: [0.1]
================ Train on the train set ================
Epoch [31/100] |	Loss: 0.607 	Average Acc: 0.801 
learning rate: [0.1]
================ Train on the train set ================
Epoch [32/100] |	Loss: 0.617 	Average Acc: 0.800 
learning rate: [0.1]
================ Train on the train set ================
Epoch [33/100] |	Loss: 0.600 	Average Acc: 0.805 
learning rate: [0.1]
================ Train on the train set ================
Epoch [34/100] |	Loss: 0.609 	Average Acc: 0.801 
================ Test on the test set ================
 * Average Acc: 0.540 Best acc 0.590
 Per-Task Acc:[0.54]
learning rate: [0.1]
================ Train on the train set ================
Epoch [35/100] |	Loss: 0.587 	Average Acc: 0.812 
learning rate: [0.1]
================ Train on the train set ================
Epoch [36/100] |	Loss: 0.600 	Average Acc: 0.809 
learning rate: [0.1]
================ Train on the train set ================
Epoch [37/100] |	Loss: 0.603 	Average Acc: 0.807 
learning rate: [0.1]
================ Train on the train set ================
Epoch [38/100] |	Loss: 0.613 	Average Acc: 0.802 
learning rate: [0.1]
================ Train on the train set ================
Epoch [39/100] |	Loss: 0.544 	Average Acc: 0.822 
================ Test on the test set ================
 * Average Acc: 0.570 Best acc 0.590
 Per-Task Acc:[0.57]
learning rate: [0.1]
================ Train on the train set ================
Epoch [40/100] |	Loss: 0.553 	Average Acc: 0.819 
learning rate: [0.1]
================ Train on the train set ================
Epoch [41/100] |	Loss: 0.597 	Average Acc: 0.812 
learning rate: [0.1]
================ Train on the train set ================
Epoch [42/100] |	Loss: 0.594 	Average Acc: 0.808 
learning rate: [0.1]
================ Train on the train set ================
Epoch [43/100] |	Loss: 0.551 	Average Acc: 0.823 
learning rate: [0.1]
================ Train on the train set ================
Epoch [44/100] |	Loss: 0.559 	Average Acc: 0.821 
================ Test on the test set ================
 * Average Acc: 0.570 Best acc 0.590
 Per-Task Acc:[0.57]
learning rate: [0.1]
================ Train on the train set ================
Epoch [45/100] |	Loss: 0.517 	Average Acc: 0.836 
learning rate: [0.1]
================ Train on the train set ================
Epoch [46/100] |	Loss: 0.564 	Average Acc: 0.816 
learning rate: [0.1]
================ Train on the train set ================
Epoch [47/100] |	Loss: 0.548 	Average Acc: 0.828 
learning rate: [0.1]
================ Train on the train set ================
Epoch [48/100] |	Loss: 0.577 	Average Acc: 0.814 
learning rate: [0.1]
================ Train on the train set ================
Epoch [49/100] |	Loss: 0.573 	Average Acc: 0.817 
================ Test on the test set ================
 * Average Acc: 0.590 Best acc 0.590
 Per-Task Acc:[0.59]
learning rate: [0.1]
================ Train on the train set ================
Epoch [50/100] |	Loss: 0.532 	Average Acc: 0.831 
learning rate: [0.1]
================ Train on the train set ================
Epoch [51/100] |	Loss: 0.539 	Average Acc: 0.826 
learning rate: [0.1]
================ Train on the train set ================
Epoch [52/100] |	Loss: 0.543 	Average Acc: 0.825 
learning rate: [0.1]
================ Train on the train set ================
Epoch [53/100] |	Loss: 0.559 	Average Acc: 0.819 
learning rate: [0.1]
================ Train on the train set ================
Epoch [54/100] |	Loss: 0.550 	Average Acc: 0.825 
================ Test on the test set ================
 * Average Acc: 0.580 Best acc 0.590
 Per-Task Acc:[0.58]
learning rate: [0.1]
================ Train on the train set ================
Epoch [55/100] |	Loss: 0.538 	Average Acc: 0.829 
learning rate: [0.1]
================ Train on the train set ================
Epoch [56/100] |	Loss: 0.524 	Average Acc: 0.830 
learning rate: [0.1]
================ Train on the train set ================
Epoch [57/100] |	Loss: 0.537 	Average Acc: 0.830 
learning rate: [0.1]
================ Train on the train set ================
Epoch [58/100] |	Loss: 0.531 	Average Acc: 0.830 
learning rate: [0.1]
================ Train on the train set ================
Epoch [59/100] |	Loss: 0.520 	Average Acc: 0.834 
================ Test on the test set ================
 * Average Acc: 0.580 Best acc 0.590
 Per-Task Acc:[0.58]
learning rate: [0.1]
================ Train on the train set ================
Epoch [60/100] |	Loss: 0.509 	Average Acc: 0.838 
learning rate: [0.1]
================ Train on the train set ================
Epoch [61/100] |	Loss: 0.550 	Average Acc: 0.820 
learning rate: [0.1]
================ Train on the train set ================
Epoch [62/100] |	Loss: 0.516 	Average Acc: 0.836 
learning rate: [0.1]
================ Train on the train set ================
Epoch [63/100] |	Loss: 0.515 	Average Acc: 0.832 
learning rate: [0.1]
================ Train on the train set ================
Epoch [64/100] |	Loss: 0.556 	Average Acc: 0.819 
================ Test on the test set ================
 * Average Acc: 0.570 Best acc 0.590
 Per-Task Acc:[0.57]
learning rate: [0.1]
================ Train on the train set ================
Epoch [65/100] |	Loss: 0.492 	Average Acc: 0.840 
learning rate: [0.1]
================ Train on the train set ================
Epoch [66/100] |	Loss: 0.497 	Average Acc: 0.839 
learning rate: [0.1]
================ Train on the train set ================
Epoch [67/100] |	Loss: 0.565 	Average Acc: 0.817 
learning rate: [0.1]
================ Train on the train set ================
Epoch [68/100] |	Loss: 0.512 	Average Acc: 0.836 
learning rate: [0.1]
================ Train on the train set ================
Epoch [69/100] |	Loss: 0.523 	Average Acc: 0.832 
================ Test on the test set ================
 * Average Acc: 0.550 Best acc 0.590
 Per-Task Acc:[0.55]
learning rate: [0.1]
================ Train on the train set ================
Epoch [70/100] |	Loss: 0.563 	Average Acc: 0.819 
learning rate: [0.1]
================ Train on the train set ================
Epoch [71/100] |	Loss: 0.510 	Average Acc: 0.838 
learning rate: [0.1]
================ Train on the train set ================
Epoch [72/100] |	Loss: 0.498 	Average Acc: 0.837 
learning rate: [0.1]
================ Train on the train set ================
Epoch [73/100] |	Loss: 0.478 	Average Acc: 0.850 
learning rate: [0.1]
================ Train on the train set ================
Epoch [74/100] |	Loss: 0.527 	Average Acc: 0.830 
================ Test on the test set ================
 * Average Acc: 0.530 Best acc 0.590
 Per-Task Acc:[0.53]
learning rate: [0.1]
================ Train on the train set ================
Epoch [75/100] |	Loss: 0.506 	Average Acc: 0.835 
learning rate: [0.1]
================ Train on the train set ================
Epoch [76/100] |	Loss: 0.530 	Average Acc: 0.828 
learning rate: [0.1]
================ Train on the train set ================
Epoch [77/100] |	Loss: 0.488 	Average Acc: 0.840 
learning rate: [0.1]
================ Train on the train set ================
Epoch [78/100] |	Loss: 0.506 	Average Acc: 0.839 
learning rate: [0.1]
================ Train on the train set ================
Epoch [79/100] |	Loss: 0.512 	Average Acc: 0.833 
================ Test on the test set ================
 * Average Acc: 0.570 Best acc 0.590
 Per-Task Acc:[0.57]
learning rate: [0.1]
================ Train on the train set ================
Epoch [80/100] |	Loss: 0.514 	Average Acc: 0.834 
learning rate: [0.1]
================ Train on the train set ================
Epoch [81/100] |	Loss: 0.528 	Average Acc: 0.835 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [82/100] |	Loss: 0.183 	Average Acc: 0.948 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [83/100] |	Loss: 0.065 	Average Acc: 0.989 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [84/100] |	Loss: 0.039 	Average Acc: 0.995 
================ Test on the test set ================
 * Average Acc: 0.680 Best acc 0.680
 Per-Task Acc:[0.68]
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [85/100] |	Loss: 0.026 	Average Acc: 0.998 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [86/100] |	Loss: 0.019 	Average Acc: 0.999 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [87/100] |	Loss: 0.016 	Average Acc: 0.999 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [88/100] |	Loss: 0.014 	Average Acc: 0.999 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [89/100] |	Loss: 0.012 	Average Acc: 0.999 
================ Test on the test set ================
 * Average Acc: 0.690 Best acc 0.690
 Per-Task Acc:[0.69]
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [90/100] |	Loss: 0.010 	Average Acc: 1.000 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [91/100] |	Loss: 0.010 	Average Acc: 1.000 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [92/100] |	Loss: 0.009 	Average Acc: 1.000 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [93/100] |	Loss: 0.009 	Average Acc: 1.000 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [94/100] |	Loss: 0.009 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.700 Best acc 0.700
 Per-Task Acc:[0.7]
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [95/100] |	Loss: 0.007 	Average Acc: 1.000 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [96/100] |	Loss: 0.007 	Average Acc: 1.000 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [97/100] |	Loss: 0.007 	Average Acc: 1.000 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [98/100] |	Loss: 0.007 	Average Acc: 1.000 
learning rate: [0.010000000000000002]
================ Train on the train set ================
Epoch [99/100] |	Loss: 0.006 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.690 Best acc 0.700
 Per-Task Acc:[0.69]
================Task 1 Start!================
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.03333333333333333
    maximize: False
    momentum: 0.95
    nesterov: False
    weight_decay: 0.0002
)
================Task 1 Training!================
The training samples number: 10000
learning rate: [0.03333333333333333]
================ Train on the train set ================
