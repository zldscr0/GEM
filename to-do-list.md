### 主要代码

##### 尽量不要修改

`run_trainer.py`

`core/trainer.py`

改动：

1.`core/trainer.py`中的`_train`

##### 复现代码

模型定义`core/model/replay/gem.py`

模型参数`config/gem.yaml`

##### 目前存在问题

- [x] 1.`gem.py`的模型还没有定义分类头

  已解决

- [x] 2.task0跑通，task1未跑通

  已全部跑通

- [ ] 3.memory和buffer应该是一类东西，需要再确定一下数据存储策略是什么

  采用ring buffer的存储方式，类似队列

- [x] 4.现在做的似乎是任务级增量学习，而不是类增量学习

  已修改

- [x] 5.在旧任务上表现非常差（acc=0），需要查看一下输出策略是不是有问题（offset1

  已修改，确实是forward中offset1设置的问题

- [x] 6.每次输出的loss为0，需要检查observe函数输出的loss值是不是有问题

  已修改，`core/trainer`里的_train没有回传loss值

- [ ] 7.虽然旧任务acc不全为0，但是性能依旧差，怀疑是memory存储有问题

  (1把buffer删了，正在做对比实验

  (2把buffer删了后前面任务acc为0

  (3修改了ptloss的计算方法（不加掩码），删除buffer前面任务acc不为0

- [ ] 8.task0（20类）的性能按理来说不应该与其它版本的gem复现相差太大，如pyCIL中的gem实现，但task0的准确率稳定在0.63这个数字，跑了pyCIL库，准确率大概在0.8左右(同一个任务，超参数设置差不多)

- [ ] 9.pyCIL中的实现有mask，跟我的理解有一点出入，问题【4】与本问题有关系

> 注：torch版本较低时会报一个错，建议安装较高版本的torch



##### 待做

~~1.跑通代码初步测试精度~~

2.给代码加上注释，详细排查复现后的问题

3.与原文精度对比



##### 精度

| id   | task-0 | task-1 | task-2 | task-3 | task-4 | 训练时长(s)       |
| ---- | ------ | ------ | ------ | ------ | ------ | ----------------- |
| 1    | 0.64   | 0.385  | 0.257  | 0.190  | 0.156  | 5640.173743247986 |
| 2    | 0.63   | 0.395  | 0.280  |        |        |                   |
|      |        |        |        |        |        |                   |

日志存储位置

1:`log/GEM-resnet18-epoch25-23-11-07-18-14-34.log`